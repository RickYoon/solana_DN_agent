import { NextRequest, NextResponse } from "next/server";
import { ChatOpenAI } from "@langchain/openai";
import { MemorySaver } from "@langchain/langgraph";
import { createReactAgent } from "@langchain/langgraph/prebuilt";
import { SolanaAgentKit, createSolanaTools } from "solana-agent-kit";

const llm = new ChatOpenAI({
  temperature: 0.7,
  model: "gpt-4o-mini",
});

const solanaAgent = new SolanaAgentKit(
  process.env.SOLANA_PRIVATE_KEY!,
  process.env.RPC_URL,
  process.env.OPENAI_API_KEY!,
);

const tools = createSolanaTools(solanaAgent);
const memory = new MemorySaver();

const agent = createReactAgent({
  llm,
  tools,
  checkpointSaver: memory,
  messageModifier: `
      ë‹¹ì‹ ì€ ë¸íƒ€ë‰´íŠ¸ëŸ´ íŒŒë° ì „ëµì„ ì‹¤í–‰í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
      
      ì‚¬ìš©ìê°€ "íˆ¬ì ì‹œì‘"ì´ë¼ê³  í•˜ë©´, USDC íˆ¬ì ê¸ˆì•¡ì„ ë¬¼ì–´ë³´ì„¸ìš”.
      
      ì‚¬ìš©ìê°€ USDC ê¸ˆì•¡ì„ ì…ë ¥í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”:

      ğŸ”¹ ë¡± í¬ì§€ì…˜ ìƒì„¸
      ê¸°ë³¸ ìŠ¤í…Œì´í‚¹ ì´ìœ¨: 12.5%
      ë¦¬ìŠ¤í…Œì´í‚¹ ë³´ë„ˆìŠ¤: Fragmetric F point x4
      Rate-X LP ìˆ˜ìµ: ì—° 8.6% + 4x Rate point

      ğŸ”¹ ìˆ í¬ì§€ì…˜
      í€ë”©í”¼ ìˆ˜ìµ: ì—° 8.6% (Drift-Protocol)

      ğŸ“ˆ ì˜ˆìƒ ìˆ˜ìµë¥  ê³„ì‚°
      - ì˜ˆìƒ ì´ ìˆ˜ìµë¥ : ì—° 32.7%
      - ì¼ ìˆ˜ìµ: [ì…ë ¥ëœ USDCì˜ 32.7% / 365]
      - ì—° ìˆ˜ìµ: [ì…ë ¥ëœ USDCì˜ 32.7%]

      ë§ˆì§€ë§‰ì— "[ğŸ’¡ íˆ¬ì ì‹¤í–‰ì„ ì‹œì‘í• ê¹Œìš”?]"ë¼ê³  ë¬¼ì–´ë³´ì„¸ìš”.

      ì‚¬ìš©ìê°€ "ë„¤" ë˜ëŠ” ê¸ì •ì ì¸ ë‹µë³€ì„ í•˜ë©´ íˆ¬ì ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
    `,
});

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];

    const eventStream = agent.streamEvents(
      {
        messages,
      },
      {
        version: "v2",
        configurable: {
          thread_id: "Delta Neutral Farming Strategy",
        },
      },
    );

    const textEncoder = new TextEncoder();
    const transformStream = new ReadableStream({
      async start(controller) {
        for await (const { event, data } of eventStream) {
          if (event === "on_chat_model_stream") {
            if (data.chunk.content) {
              controller.enqueue(textEncoder.encode(data.chunk.content));
            }
          }
        }
        controller.close();
      },
    });

    return new Response(transformStream);
  } catch (e: any) {
    return NextResponse.json({ error: e.message }, { status: e.status ?? 500 });
  }
}